# -*- coding: utf-8 -*-
"""FINITO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ccBE4cpJeAcTSo5BFlPq81UxiOAV0hME
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Installing ARIMA package"""

pip install pmdarima

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from google.colab import files
from statsmodels.tsa.arima_model import ARIMA

#Reading .csv file(Floating car data) which is raw data and its plot.

def parser(x):
    return datetime.strptime(x, '%Y-%m-%d %H:%M:%S')


df = pd.read_csv('/content/drive/MyDrive/FCD_aggregated_10k.csv',header = 0, index_col=0, parse_dates=[0], date_parser=parser)
print(df.head())

plt.figure(figsize=(15,10))
df['speed'].plot()

#Preprocessing the data

#condition1 -- if counts equal to zero then the speed and the std must be zero or null.
check = df.loc[df.counts == 0.0, ['speed', 'std']]
print(check)

print(check.isnull().sum())

#condition2 -- if counts equal to one then the speed must be zero or null and and the std must be zero or null.
check1 = df.loc[df.counts == 1, ['speed', 'std']]
print(check1)

print(check1.isnull().sum())

#condition3 -- if counts equal to greater than one then the speed and the std must not be zero or null.
check2 = df.loc[df.counts > 1, ['speed', 'std']]
print(check2)

print(check2.isnull().sum())

#Preprocessed data
#From the above checks we can simply fill Nan values with zero
df1 = df.fillna(0)
print(df1.head())

print(df1.shape)

df2 = df1['speed']

#Plotting graph among preprocessed data, Hourly mean data, Daily mean data
df2_mean = df2.rolling(window = 12).mean()
df2_mean_daily = df2.rolling(window = 288).mean()

plt.figure(figsize=(15,10))


plt.xlabel('Comparision of 5min, hourly, daily mean data')

ax1 = df2.plot(color='blue', grid=True, label='5 min mean speed')
ax2 = df2_mean.plot(color='red', grid=True, label='hourly mean speed')
ax3 = df2_mean_daily.plot(color='black', grid=True,label='Daily mean speed')

h1, l1 = ax1.get_legend_handles_labels()
h2, l2 = ax2.get_legend_handles_labels()
h3, l3 = ax3.get_legend_handles_labels()

plt.legend()
plt.show()

plt.figure(figsize=(15,10))
fcd = df['speed'].fillna(0)

fcd.index = fcd.index.to_period('M')
# Fitting the ARIMA model
model = ARIMA(fcd, order=(3,1,0))
model_fit = model.fit()

print(model_fit.summary())
# plotting residuals 
residuals = DataFrame(model_fit.resid)
residuals.plot()
pyplot.show()

print(residuals.describe())

# Creating train and test data

X = fcd.values
size = int(len(X) * 0.75)
train, test = X[0:size], X[size:len(X)]
history = [x for x in train]
predictions = list()
# validatin of data
for t in range(len(test)):
  model = ARIMA(history, order=(2,1,0))
  model_fit = model.fit()
  output = model_fit.forecast()
  ciao = output[0]
  predictions.append(ciao)
  prego = test[t]
  history.append(prego)
  print('predicted=%f, expected=%f' % (ciao, prego))

"""plotting between forecast and actual values"""

plt.figure(figsize=(15,10))
pyplot.plot(test)
pyplot.plot(predictions, color='red')
pyplot.show()

#Calculating Root mean squared error
from sklearn.metrics import mean_squared_error
from math import sqrt

sqrt(mean_squared_error(test, predictions))

#Calculating mean absolute error
from sklearn.metrics import mean_absolute_error
import numpy as np

mean_absolute_error(test, predictions, multioutput='raw_values')

#Calculating mean absolute percentage error
def mean_absolute_percentage_error(test, predictions):
    
  MAPE = []

  for i in range(len(test)):
    x = test[i]
    y = predictions[i]
    if x == 0:
      pass
    else:
      MAPE.append(np.abs((x-y)/x) * 100)
  return np.mean(MAPE)
  

mean_absolute_percentage_error(test, predictions)

len(test)

len(predictions)

#Calculating absolute percentage error greater than 10%
def mean_absolute_percentage_error1(test, predictions):
    
  MAPE0 = []
  

  for i in range(len(test)):
    x = test[i]
    y = predictions[i]
    if x == 0:
      pass
    else:
      B = np.abs((x-y)/x) * 100
      if B >10:
        MAPE0.append(B)


  return ((len(MAPE0)/3400)*100)
print(mean_absolute_percentage_error1(test, predictions))

#Normalization of data
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from google.colab import files
from statsmodels.tsa.arima_model import ARIMA


def parser(x):
    return datetime.strptime(x, '%Y-%m-%d %H:%M:%S')


dfr = pd.read_csv('/content/drive/MyDrive/FCD_aggregated_10k.csv', index_col=0, parse_dates=[0], date_parser=parser)
print(df.head())


ee = dfr.drop(df.columns[[0, 2, 3]], axis=1)
print(df.head())

print(ee.shape)

ee1 = ee.fillna(0)
print(ee1.head())


print(ee.min())
print(ee.max())

from sklearn.preprocessing import MinMaxScaler


# normalizing the data
ee_arr = ee1.values
ee_arr

scaler = MinMaxScaler(feature_range=(0,1))
scaler = scaler.fit(ee_arr)
print(scaler.data_min_)
print(scaler.data_max_)


ee1_normalize = scaler.transform(ee_arr)
print(ee1_normalize[20])


for i in range(30):
  print(ee1_normalize[i])

# creating the test and train data
X = ee1_normalize
size = int(len(X) * 0.75)
ee1_train, ee1_test = X[0:size], X[size:len(X)]
print(ee1_test.size)
print(ee1_train.size)

# fitting the data
from statsmodels.tsa.arima_model import ARIMA

ee1_model = ARIMA(ee1_train, order = (2,1,0))
ee1_model_fit = ee1_model.fit()

# forecating the data
ee1_forecast = ee1_model_fit.forecast(steps=2500)[0]
print(ee1_forecast)

print(ee1_test)

#errors
from sklearn.metrics import mean_squared_error
import numpy as np

print(mean_squared_error(ee1_test,ee1_forecast))

print(np.sqrt(mean_squared_error(ee1_test,ee1_forecast)))

#reversing the normalized forecast data into oringinal
ee1_forecast_array_reverse = scaler.inverse_transform(ee1_forecast.reshape(1,-1))
print(ee1_forecast_array_reverse)

#reversing the normalized test data into oringinal
ee1_test_reverse = scaler.inverse_transform(ee1_test)
print(ee1_test_reverse)

# calculting root mean squared error
np.sqrt(mean_squared_error(ee1_test_reverse, ee1_forecast_array_reverse[0]))

# calculting mean absolute error
from sklearn.metrics import mean_absolute_error
import numpy as np

mean_absolute_error(ee1_test_reverse,ee1_forecast_array_reverse[0], multioutput='raw_values')

# calculting mean absolute percentage error
def mean_absolute_percentage_error(ee1_test_reverse,ee1_forecast_array_reverse):
    
  MAPE = []

  for i in range(len(ee1_test_reverse)):
    x = ee1_test_reverse[i]
    y = ee1_forecast_array_reverse[0]
    if x == 0:
      pass
    else:
      MAPE.append(np.abs((x-y)/x) * 100)
  return np.mean(MAPE)


mean_absolute_percentage_error(ee1_test_reverse,ee1_forecast_array_reverse)

# calculting absolute percentage error greater than 10%

def mean_absolute_percentage_error1(ee1_test_reverse,ee1_forecast_array_reverse):
    
  MAPEN = []
  

  for i in range(len(ee1_test_reverse)):
    x = ee1_test_reverse[i]
    y = ee1_forecast_array_reverse[0].any()
    if x == 0:
      pass
    else:
      F = np.abs(((x-y)/x) * 100)
      
      if F >10:
        MAPEN.append(F)


  return ((len(MAPEN)/2500)*100)
print(mean_absolute_percentage_error1(ee1_test_reverse,ee1_forecast_array_reverse))

"""Standardization of data"""

from sklearn.preprocessing import StandardScaler
# standardizing the data
std_scaler = StandardScaler()
std_scaler = std_scaler.fit(ee_arr)

print(std_scaler.mean_)
print(std_scaler.var_)

std_ee1 = std_scaler.transform(ee_arr)
print(std_ee1[5])

#creating test and train data
X = series.values
size = int(len(X) * 0.75)
std_ee1_train, std_ee1_test = X[0:size], X[size:len(X)]
history = [x for x in train]

#fitting the data
std_ee1_arima = ARIMA(std_ee1_train,order=(2,1,0))
std_ee1_arima_fit = std_ee1_arima.fit()

#forecasting the data
std_ee1_forecast = std_ee1_arima_fit.forecast(steps=2500)[0]
print(std_ee1_forecast)

print(std_ee1_test)

#reversing the normalized forecasting to original
std_ee1_forecast_reverse = std_scaler.inverse_transform(ee1_forecast)
print(std_ee1_forecast_reverse)

#reversing the normalized test data to original
std_ee1_test_reverse = std_scaler.inverse_transform(ee1_test)
print(std_ee1_test_reverse)

np.sqrt(mean_squared_error(std_ee1_test_reverse,std_ee1_forecast_reverse))

from sklearn.metrics import mean_absolute_error
import numpy as np

mean_absolute_error(std_ee1_test_reverse,std_ee1_forecast_reverse, multioutput='raw_values')

def mean_absolute_percentage_error(std_ee1_test_reverse,std_ee1_forecast_reverse): 
    std_ee1_test_reverse,std_ee1_forecast_reverse = np.array(std_ee1_test_reverse), np.array(std_ee1_forecast_reverse)
    MAPE = np.mean(np.abs((std_ee1_test_reverse - std_ee1_forecast_reverse) / std_ee1_test_reverse)) * 100
    return MAPE


mean_absolute_percentage_error(std_ee1_test_reverse,std_ee1_forecast_reverse)

def mean_absolute_percentage_error1(std_ee1_test_reverse,std_ee1_forecast_reverse):
    
  MAPE1 = []
  

  for i in range(len(std_ee1_test_reverse)):
    x = std_ee1_test_reverse[i]
    y = std_ee1_forecast_reverse[i]
    if x == 0:
      pass
    else:
      F = np.abs((x-y)/x) * 100
      if F >10:
        MAPE1.append(F)


  return ((len(MAPE1)/2500)*100)
print(mean_absolute_percentage_error1(std_ee1_test_reverse,std_ee1_forecast_reverse))

std_ee1_test_reverse,std_ee1_forecast_reverse